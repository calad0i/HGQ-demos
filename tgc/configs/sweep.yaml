seed: 123
splits: [0.7,0.1,0.2] # train, val, test
mask_thres: 0.01
data_path: ./data/fake_TGC_0.041_pruned.h5

save_path: /tmp/tgc_sweep
train:
  epochs: 60000
  cdr_args:
    initial_learning_rate: 3.e-3
    first_decay_steps: 100
    t_mul: 1
    m_mul: 0.995
    alpha: 1.e-6
  bsz: 16384
model:
  l1_cc: 2.e-6
  l1_dc: 2.e-6
  l1_act: 2.e-6
  init_bw_a: 8
  init_bw_k: 8
  masking: true
beta:
  intervals:
    - epochs: 0
      betas: [3.e-6,3.e-6]
      interpolation: linear
    - epochs: 6000
      betas: [3.e-6, 6.e-4]
      interpolation: log

